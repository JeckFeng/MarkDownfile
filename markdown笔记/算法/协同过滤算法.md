#  协同过滤算法

1. 推荐算法中放在第一位的一定是协同过滤算法了（collaborative filtering ，CF），它可以通过用户的历史数据来分析出用户之间的相似性，或者通过分析用户购买物品的数据，找出相似的物品，把它们推荐给其他用户。

2. 协同过滤的分类

- 基于用户（user-based）的协同过滤，根据用户对物品的历史行为数据，如：点击率，购买，评论，添加购物车等行为的记录，计算用户和用户的相似度找到跟用户A相识的用户B,C,D……再把这些用户喜欢的内容推荐给A用户。
- 基于物品（item-based）的协同过滤，根据用户对物品的历史评价数据，计算物品和物品之间的相似度找到跟物品1相似的物品2，3，4……再把这些物品推荐给看过这些物品1的用户们。
- 基于模型（model-based）的协同过滤。但是，在用户数量以及用户评分不足的情况下，以上两种方法都不太适用，为了解决这种问题，主要的基于模型的方法有：ALS（交替最小二乘）

3.基于用户寻找偏好相似的用户

　　我们模拟了5个用户对两件商品的评分，来说明如何通过用户对不同商品的态度和偏好寻找相似的用户。在示例中，5个用户分别对两件商品进行了评分。这里的分值可能表示真实的购买，也可以是用户对商品不同行为的量化指标。例如，浏览商品的次数，向朋友推荐商品，收藏，分享，或评论等等。这些行为都可以表示用户对商品的态度和偏好程度。

|       | 商品1 | 商品2 |
| ----- | ----- | ----- |
| userA | 3.3   | 6.5   |
| userB | 5.8   | 2.6   |
| userC | 3.6   | 6.3   |
| userD | 3.4   | 5.8   |
| userE | 5.2   | 3.1   |

计算欧氏距离评价，皮尔逊相关系数。对用户的相关性进行评价。

![](E:\markdown笔记\算法\皮尔逊相关系数.png)

 其中，E为数学期望或均值，D为方差，D开根号为标准差，E{ [X-E(X)] [Y-E(Y)]}称为随机变量X与Y的协方差，记为Cov(X,Y) 。

<img src="E:\markdown笔记\算法\相关系数计算结果.jpg" style="zoom:80%;" />





4. 基于物品推荐为相似的用户提供推荐物品 

   当我们需要对用户C推荐商品时，首先我们检查之前的相似度列表，发现用户C和用户D和E的相似度较高。换句话说这三个用户是一个群体，拥有相同的偏好。因此，我们可以对用户C推荐D和E的商品。但这里有一个问题。我们不能直接推荐前面商品1-商品5的商品。因为这这些商品用户C以及浏览或者购买过了。不能重复推荐。因此我们要推荐用户C还没有浏览或购买过的商品。

5.  寻找相似的物品 

​       表格中是两个用户对5件商品的评分。在这个表格中我们用户和商品的位置进行了互换，通过两个      用户的评分来获得5件商品之间的相似度情况。 

![](E:\markdown笔记\算法\基于物品.jpg)

计算欧氏距离评价，皮尔逊相关系数。对用户的相关性进行评价。

6.ALS算法

对于一个user-product-rating的评分数据集，ALS会建立一个user\*product的m\*n的矩阵，m为用户数量，n为商品数量。但是在这个矩阵中，并不是每个用户都会为每个商品打分，而用户和商品的数量是非常大的，所以这个矩阵往往是稀疏的。

|   评分表   | 商品1 | 商品2 | 商品3 | 商品4 |
| ---- | ----- | ----- | ----- | ----- |
| usr1 |   rating1    |       |       |       |
| usr2 |       |    ranting2   |       |       |
| usr3 |       |       |   rating3    |   rating3'   |

<img src="E:\markdown笔记\算法\评分的稀疏矩阵图.png" style="zoom: 50%;" />

ALS 的核心就是下面这个假设：打分矩阵是近似低秩的。换句话说，一个的打分矩阵
$$
A_(m*n)
$$

可以用两个小矩阵乘积来近似：
$$
A_(m*n) = U_(m*k) * V^T_{m*n}
$$








